{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14671398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp slideslive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f1be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.test import test_fail, test_warns\n",
    "from nbdev.showdoc import show_doc\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "from myslideslive.test_helper import _cd_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import tempfile\n",
    "import time\n",
    "import urllib\n",
    "import warnings\n",
    "\n",
    "from lxml.etree import HTML\n",
    "from xml.etree import ElementTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf84d24",
   "metadata": {},
   "source": [
    "# Interact with SlidesLive\n",
    "\n",
    "> This module implements easy interaction with [SlidesLive](https://slideslive.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfdee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "# Parse SlidesLive URL\n",
    "_SL_REGEX_STR = ('https?://slideslive\\\\.(?:com|de)/'\n",
    "                 '(?P<id>\\\\d+)'\n",
    "                 '/*'\n",
    "                 '(?P<name>.*)')\n",
    "SL_REGEX = re.compile(_SL_REGEX_STR)\n",
    "\n",
    "# SL INFO JSON\n",
    "SL_INFO = 'https://ben.slideslive.com/player/{id}?player_token={token}'\n",
    "# SL HTML page\n",
    "SL_HTML = 'https://slideslive.com/{id}'\n",
    "\n",
    "# SL CDNs\n",
    "SL_CDN = 'https://cdn.slideslive.com/data/presentations/{video_id}/slides/{slide_type}/{slide_id}.jpg'\n",
    "YODA_CDN = 'https://d2ygwrecguqg66.cloudfront.net/data/presentations/{id}/{data}'\n",
    "# f is file format; can be webp/png. h is height; can be 432/540/720/1080.\n",
    "RS_CDN = 'https://rs.slideslive.com/{video_id}/slides/{slide_id}.{format}?h={slide_type}&f={format}'  # can be .png or .webp # slide_type is size\n",
    "# e.g.: https://d2ygwrecguqg66.cloudfront.net/data/presentations/38956531/slides/big/00793.jpg\n",
    "#       https://d2ygwrecguqg66.cloudfront.net/data/presentations/38956531/v1/38956531.xml\n",
    "#       https://d2ygwrecguqg66.cloudfront.net/data/presentations/38956531/v1/slides.json\n",
    "\n",
    "# Slide size mapping\n",
    "SIZE_MAP = {'small':432, 'medium':540, 'large':720, 'xlarge':1080}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "_url_1 = 'https://slideslive.com/38956531/beyond-static-papers-rethinking-how-we-share-scientific-understanding-in-ml'\n",
    "_url_2 = 'https://slideslive.com/38956531/'\n",
    "_url_3 = 'https://slideslive.de/38956531'\n",
    "_id = '38956531'\n",
    "_name = 'beyond-static-papers-rethinking-how-we-share-scientific-understanding-in-ml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eefe298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "_url_1_match = SL_REGEX.search(_url_1)\n",
    "assert _url_1_match is not None\n",
    "assert _url_1_match.group('id') == _id\n",
    "assert _url_1_match.group('name') == _name\n",
    "\n",
    "_url_2_match = SL_REGEX.search(_url_2)\n",
    "assert _url_2_match is not None\n",
    "assert _url_2_match.group('id') == _id\n",
    "assert _url_2_match.group('name') == ''\n",
    "\n",
    "\n",
    "_url_3_match = SL_REGEX.search(_url_3)\n",
    "assert _url_3_match is not None\n",
    "assert _url_3_match.group('id') == _id\n",
    "assert _url_3_match.group('name') == ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39743bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "_ben_url = 'https://ben.slideslive.com/player/123?player_token=456'\n",
    "assert SL_INFO.format(id=123, token=456) == _ben_url\n",
    "assert SL_INFO.format(id='123', token='456') == _ben_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def url2id(sl_url):\n",
    "    \"\"\"Converts SlidesLive URL to presentation ID and name.\"\"\"\n",
    "    sl_url_match = SL_REGEX.search(sl_url)\n",
    "    if sl_url_match is None or not sl_url_match.group('id'):\n",
    "        raise Exception('Could not parse the SlidesLive URL.')\n",
    "\n",
    "    return sl_url_match.group('id'), sl_url_match.group('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "test_fail(url2id,\n",
    "          args=['incorrect.url'],\n",
    "          contains='Could not parse the SlidesLive URL.')\n",
    "\n",
    "assert url2id(_url_1) == (_id, _name)\n",
    "assert url2id(_url_2) == (_id, '')\n",
    "assert url2id(_url_3) == (_id, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cbfe8a",
   "metadata": {},
   "source": [
    "This function parses SlidesLIve URL into the presentation ID and name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c1842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('38956531',\n",
       " 'beyond-static-papers-rethinking-how-we-share-scientific-understanding-in-ml')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl_url = ('https://slideslive.com/38956531/'\n",
    "          'beyond-static-papers-rethinking-how-we-share-scientific-understanding-in-ml')\n",
    "my_sl_id, my_sl_name = url2id(sl_url)\n",
    "\n",
    "my_sl_id, my_sl_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88172b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_sl_info(sl_id):\n",
    "    \"\"\"Pulls information about a SlidesLive presentation.\"\"\"\n",
    "    if (not isinstance(sl_id, int)\n",
    "          and (isinstance(sl_id, str) and not sl_id.isdecimal())):\n",
    "        raise TypeError('Incorrect SlidesLive ID format.')\n",
    "\n",
    "    # get player token\n",
    "    html_source_url = SL_HTML.format(id=sl_id)\n",
    "    html_source_request = requests.get(html_source_url)\n",
    "    html_source = HTML(html_source_request.content.decode())\n",
    "    sl_token = html_source.xpath('//div[@data-player-token]/@data-player-token')\n",
    "    if not isinstance(sl_token, list) or len(sl_token) != 1:\n",
    "        raise RuntimeError('Could not retrieve the data player token. '\n",
    "                           'Please report this error.')\n",
    "    sl_token = sl_token[0]\n",
    "\n",
    "    info_url = SL_INFO.format(id=sl_id, token=sl_token)\n",
    "    info_request = requests.get(info_url).content.decode()\n",
    "\n",
    "    _m3u_header = '#EXTM3U'\n",
    "    if info_request.startswith(_m3u_header):\n",
    "        info_request_list = info_request.split('\\n')\n",
    "        assert info_request_list[0] == _m3u_header\n",
    "        del info_request_list[0]\n",
    "\n",
    "        info_json = {}\n",
    "        for i in info_request_list:\n",
    "            assert ':' in i\n",
    "            i = i.split(':')\n",
    "            key, val = i[0], ':'.join(i[1:])\n",
    "            for pre in ['#EXT-SL-PRESENTATION-', '#EXT-SL-VOD-', '#EXT-SL-']:\n",
    "                if key.startswith(pre):\n",
    "                    key = key[len(pre):].lower().replace('-', '_')\n",
    "            assert key not in info_json\n",
    "            info_json[key] = val\n",
    "    else:\n",
    "        info_json = json.loads(info_request)\n",
    "\n",
    "    return info_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05127f9",
   "metadata": {},
   "source": [
    "Pulls video presentation details from SlidesLive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34fee7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': '1',\n",
       " 'account_id': '84503',\n",
       " 'id': '38956531',\n",
       " 'title': 'Beyond Static Papers: Rethinking How We Share Scientific Understanding in ML',\n",
       " 'updated_at': '2023-10-20T15:29:03Z',\n",
       " 'player_type': 'video_slideshow',\n",
       " 'start_time': '2494000',\n",
       " 'thumbnail': 'https://ma.slideslive.com/library/presentations/38956531/thumbnail/beyond-static-papers-rethinking-how-we-share-scientific-understanding-in-ml_ebgwSR_big.jpg',\n",
       " 'slideslive_logo_visible': 'false',\n",
       " 'slideslive_logo_linkify': 'false',\n",
       " 'custom_cmcd_tracking': 'false',\n",
       " 'playlist_type': 'vod',\n",
       " 'media_set_id': '119992',\n",
       " 'video_service_name': 'yoda',\n",
       " 'video_id': 'oHAAFl-q6gQx',\n",
       " 'video_ken_enabled': 'true',\n",
       " 'video_servers': '[\"1159783934.rsc.cdn77.org\",\"1511376917.rsc.cdn77.org\"]',\n",
       " 'slides_xml_url': 'https://s.slideslive.com/38956531/v1/38956531.xml?1650713664',\n",
       " 'slides_json_url': 'https://s.slideslive.com/38956531/v1/slides.json?1650713664',\n",
       " 'subtitles': '[{\"name\":\"English\",\"language\":\"en\",\"subtitles_id\":56748,\"webvtt_url\":\"https://slideslive-video-subtitles.s3.amazonaws.com/56748/subtitles.vtt?X-Amz-Algorithm=AWS4-HMAC-SHA256\\\\u0026X-Amz-Credential=AKIAXWNGJW2E2DUNCDBO%2F20240226%2Fus-east-1%2Fs3%2Faws4_request\\\\u0026X-Amz-Date=20240226T160358Z\\\\u0026X-Amz-Expires=86400\\\\u0026X-Amz-SignedHeaders=host\\\\u0026X-Amz-Signature=7d6870947f23ebace62fc128cf1d881b43a1d536da425d85fc3454974026cdf7\"}]'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sl_info(my_sl_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "test_fail(get_sl_info,\n",
    "          args=['id'],\n",
    "          contains='Incorrect SlidesLive ID format.')\n",
    "\n",
    "_sl_info = get_sl_info(_id)\n",
    "assert isinstance(_sl_info, dict)\n",
    "assert _sl_info['title'].lower().replace(':', '') == _name.replace('-', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4323c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide\n",
    "def parse_slide_xml(xml, mode='string'):\n",
    "    \"\"\"\n",
    "    Parse the SlidesLive slide XML metadata.\n",
    "\n",
    "    `mode` can either be `string` or `file`.\n",
    "    \"\"\"\n",
    "    if mode not in ('string', 'file'):\n",
    "        raise ValueError('The xml parse mode can either be *string* or *file*.')\n",
    "\n",
    "    slide_properties = ['orderId', 'timeSec', 'time', 'slideName']\n",
    "\n",
    "    if mode == 'string':\n",
    "        xml_root = ElementTree.fromstring(xml)\n",
    "    else:\n",
    "        assert mode == 'file'\n",
    "        with open(xml, 'r') as f:\n",
    "            xml_tree = ElementTree.parse(f)\n",
    "        xml_root = xml_tree.getroot()\n",
    "    if xml_root.tag != 'videoContent':\n",
    "        raise RuntimeError(f'Cannot process this XML structure: {xml_root.tag}.')\n",
    "\n",
    "    slides = []\n",
    "    for node in xml_root:\n",
    "        if node is None:\n",
    "            continue\n",
    "        if node.tag != 'slide':\n",
    "            raise RuntimeError(f'Unexpected slide type: {node.tag}.')\n",
    "\n",
    "        slide = {}\n",
    "        for n in node:\n",
    "            if n.tag not in slide_properties:\n",
    "                raise RuntimeError(f'Unexpected slide specifier: {n.tag}.')\n",
    "            slide[n.tag] = n.text\n",
    "        slides.append(slide)\n",
    "\n",
    "    return slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# This function processes the XML representation of SlidesLive slides metadata\n",
    "# and returns its JSON representation.\n",
    "# This XML structure can either be read from a file (`mode='file'`) or a string\n",
    "# (`mode='string'`, *default*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba94ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "sl_xml = '''\n",
    "<videoContent>\n",
    "  <slide>\n",
    "    <orderId>1</orderId>\n",
    "    <timeSec>0</timeSec>\n",
    "    <time>0</time>\n",
    "    <slideName>00001</slideName>\n",
    "  </slide>\n",
    "  <slide>\n",
    "    <orderId>2</orderId>\n",
    "    <timeSec>1382</timeSec>\n",
    "    <time>1382073</time>\n",
    "    <slideName>00002</slideName>\n",
    "  </slide>\n",
    "</videoContent>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d1d3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'orderId': '1', 'timeSec': '0', 'time': '0', 'slideName': '00001'},\n",
       " {'orderId': '2', 'timeSec': '1382', 'time': '1382073', 'slideName': '00002'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "parse_slide_xml(sl_xml, mode='string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bf6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'orderId': '1', 'timeSec': '0', 'time': '0', 'slideName': '00001'},\n",
       " {'orderId': '2', 'timeSec': '1382', 'time': '1382073', 'slideName': '00002'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "xml_file = tempfile.NamedTemporaryFile(mode='w+b')\n",
    "xml_file.write(sl_xml.encode())\n",
    "xml_file.seek(0)\n",
    "\n",
    "parse_slide_xml(xml_file.name, mode='file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3aadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "_unexpected_xml_1 = '''\n",
    "<content>\n",
    "  <element>\n",
    "    <orderId>1</orderId>\n",
    "    <timeSec>0</timeSec>\n",
    "    <foo>bar</foo>\n",
    "    <time>0</time>\n",
    "    <slideName>00001</slideName>\n",
    "  </element>\n",
    "</content>\n",
    "'''\n",
    "_unexpected_xml_2 = '''\n",
    "<videoContent>\n",
    "  <element>\n",
    "    <orderId>1</orderId>\n",
    "    <timeSec>0</timeSec>\n",
    "    <foo>bar</foo>\n",
    "    <time>0</time>\n",
    "    <slideName>00001</slideName>\n",
    "  </element>\n",
    "</videoContent>\n",
    "'''\n",
    "_unexpected_xml_3 = '''\n",
    "<videoContent>\n",
    "  <slide>\n",
    "    <orderId>1</orderId>\n",
    "    <timeSec>0</timeSec>\n",
    "    <foo>bar</foo>\n",
    "    <time>0</time>\n",
    "    <slideName>00001</slideName>\n",
    "  </slide>\n",
    "</videoContent>\n",
    "'''\n",
    "test_fail(parse_slide_xml,\n",
    "          args=[_unexpected_xml_1],\n",
    "          kwargs=dict(mode='str'),\n",
    "          contains='The xml parse mode can either be *string* or *file*.')\n",
    "test_fail(parse_slide_xml,\n",
    "          args=[_unexpected_xml_1],\n",
    "          kwargs=dict(mode='string'),\n",
    "          contains='Cannot process this XML structure: content.')\n",
    "test_fail(parse_slide_xml,\n",
    "          args=[_unexpected_xml_2],\n",
    "          kwargs=dict(mode='string'),\n",
    "          contains='Unexpected slide type: element.')\n",
    "test_fail(parse_slide_xml,\n",
    "          args=[_unexpected_xml_3],\n",
    "          kwargs=dict(mode='string'),\n",
    "          contains='Unexpected slide specifier: foo.')\n",
    "\n",
    "_xml_string = parse_slide_xml(xml_file.name, mode='file')\n",
    "_xml_file = parse_slide_xml(xml_file.name, mode='file')\n",
    "assert isinstance(_xml_string, list)\n",
    "assert isinstance(_xml_string[0], dict)\n",
    "assert _xml_string[0]['orderId'] == '1'\n",
    "assert _xml_string[1]['orderId'] == '2'\n",
    "assert isinstance(_xml_file, list)\n",
    "assert isinstance(_xml_file[0], dict)\n",
    "assert _xml_file[0]['orderId'] == '1'\n",
    "assert _xml_file[1]['orderId'] == '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c39176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "xml_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e471440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_slide_metadata(sl_meta_url, approach='json'):\n",
    "    \"\"\"\n",
    "    Processes metadata of slides associated with a SlidesLive presentation.\n",
    "\n",
    "    `approach` is one of `json` or `xml`.\n",
    "    It specifies the strategy for extracting slide metadata.\n",
    "    \"\"\"\n",
    "    if approach not in ('xml', 'json'):\n",
    "        raise ValueError('The approach can either be *json* or *xml*.')\n",
    "\n",
    "    meta_request = requests.get(sl_meta_url)\n",
    "    if not meta_request.ok:\n",
    "        raise RuntimeError(f'Request failed ({sl_meta_url})')\n",
    "\n",
    "    meta_content = meta_request.content.decode()\n",
    "    if approach == 'json':\n",
    "        meta_data = json.loads(meta_content)\n",
    "    else:\n",
    "        assert approach == 'xml'\n",
    "        meta_data_ = parse_slide_xml(meta_content)\n",
    "        meta_data_ = {int(d['orderId']): {'time': int(float(d['time'])),\n",
    "                                          'type': 'image',\n",
    "                                          'image': {'name': d['slideName']}}\n",
    "                      for d in meta_data_}\n",
    "        meta_data = {'slides': [meta_data_[i] for i in sorted(meta_data_.keys())]}\n",
    "\n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1040e22f",
   "metadata": {},
   "source": [
    "This function extracts the synchronisation between slide images and video presentation.\n",
    "This information can either be pulled from XML (`approach='xml'`) or\n",
    "JSON (`approach='json'`, *default*) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc86d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['big', 'medium']\n",
      "{'time': 0, 'type': 'image', 'image': {'name': '00001'}}\n"
     ]
    }
   ],
   "source": [
    "slides_structure_json = 'https://cdn.slideslive.com/data/presentations/38956531/v1/slides.json'\n",
    "slides_metadata = get_slide_metadata(slides_structure_json)\n",
    "\n",
    "print(slides_metadata.get('slide_qualities'))\n",
    "print(slides_metadata.get('slides')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "test_fail(get_slide_metadata,\n",
    "          args=['url'],\n",
    "          kwargs=dict(approach='foo'),\n",
    "          contains='The approach can either be *json* or *xml*.')\n",
    "\n",
    "test_url = 'https://s.slideslive.com/38988636/v4/38988636.xml?1661984709'\n",
    "test_fail(get_slide_metadata,\n",
    "          args=[test_url],\n",
    "          kwargs=dict(approach='xml'),\n",
    "          contains=f'Request failed ({test_url})')\n",
    "\n",
    "_meta_json = 'https://cdn.slideslive.com/data/presentations/38956531/v1/slides.json?1624456122'\n",
    "_meta_json_proc = get_slide_metadata(_meta_json, 'json')\n",
    "_meta_xml = 'https://cdn.slideslive.com/data/presentations/38956531/v1/38956531.xml?1624456122'\n",
    "_meta_xml_proc = get_slide_metadata(_meta_xml, 'xml')\n",
    "\n",
    "assert 'slide_qualities' in _meta_json_proc\n",
    "assert 'slide_qualities' not in _meta_xml_proc\n",
    "\n",
    "assert 'slides' in _meta_json_proc\n",
    "assert 'slides' in _meta_xml_proc\n",
    "\n",
    "for i, j in zip(_meta_json_proc['slides'], _meta_xml_proc['slides']):\n",
    "    assert i == j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf766ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_urls(video_id, slide_meta, slide_type='xlarge', slide_format='png',\n",
    "             slide=(None, None), time=(None, None)):\n",
    "    \"\"\"\n",
    "    Composes a list of URLs for slides of a given SlidesLive presentation.\n",
    "\n",
    "    `video_id` specifies the ID of a SlidesLive presentation.\n",
    "    `slide_meta` is the metadata of a SlidesLive presentation\n",
    "    as given by the `get_slide_metadata` function.\n",
    "    `slide_type` specifies the size of the slide.\n",
    "    `slide_format` specifies the image format of the slide.\n",
    "\n",
    "    A subset of slides may be extracted with this function using either\n",
    "    the `slide` or `time` parameter (but not both simultaneously).\n",
    "\n",
    "    The `slide` parameter takes a range of slides to be extracted based\n",
    "    on the slide ID numbers visible in a SlidesLive presentation.\n",
    "    For example, `slide=(5, 7)` to extract slides 5--7, **inclusive**;\n",
    "    `slide=(5, None)` to extract from slide 5 **onwards**; or\n",
    "    `slide=(None, 6)` to extract up to slide 6 **inclusive**.\n",
    "\n",
    "    The `time` parameter takes a range of time (visible in a SlidesLive\n",
    "    presentation) for which slides are to be extracted.\n",
    "    For example, `time=(5, 10)` to extract slides starting at second 5\n",
    "    (**inclusive**) and ending before second 10 (**exclusive**);\n",
    "    `time=(5, None)` to extract from second 5 **onwards**; or\n",
    "    `time=(None, 50)` to extract up to second 60 **exclusive**.\n",
    "    \"\"\"\n",
    "    if not isinstance(slide, tuple) or len(slide) != 2:\n",
    "        raise TypeError('Numeric slide bound (slide) must be a 2-tuple.')\n",
    "    if not isinstance(time, tuple) or len(time) != 2:\n",
    "        raise TypeError('Time-based slide bound (time) must be a 2-tuple.')\n",
    "\n",
    "    slide_given = slide[0] is not None or slide[1] is not None\n",
    "    time_given = time[0] is not None or time[1] is not None\n",
    "    if slide_given and time_given:\n",
    "        raise RuntimeError('Both slide and time bounds cannot be used simultaneously.')\n",
    "\n",
    "    if slide_type not in SIZE_MAP:\n",
    "        _vals = [f'\"{i}\"' for i in sorted(list(SIZE_MAP.keys()))]\n",
    "        raise ValueError(f'The slide type (slide_type={slide_type}) can only '\n",
    "                         f'be one of the following: {\", \".join(_vals)}.')\n",
    "    slide_size = SIZE_MAP[slide_type]\n",
    "\n",
    "    if slide_format not in ('png', 'webp'):\n",
    "        raise ValueError(f'The slide format (slide_format={slide_format}) can either be \"png\" or \"webp\".')\n",
    "\n",
    "    slides = []\n",
    "    if slide_given:\n",
    "        lower_bound = -float('inf') if slide[0] is None else slide[0]\n",
    "        upper_bound = float('inf') if slide[1] is None else slide[1]\n",
    "        for i, s in enumerate(slide_meta['slides']):\n",
    "            i_ = i + 1\n",
    "            if i_ >= lower_bound and i_ <= upper_bound:\n",
    "                slides.append(RS_CDN.format(\n",
    "                    video_id=video_id,\n",
    "                    slide_type=slide_size,\n",
    "                    slide_id=s['image']['name'],\n",
    "                    format=s['image'].get('extname', slide_format).strip('.')))\n",
    "    elif time_given:\n",
    "        lower_bound = -float('inf') if time[0] is None else time[0]\n",
    "        upper_bound = float('inf') if time[1] is None else time[1]\n",
    "        s = slide_meta['slides']\n",
    "        for i in range(0, len(s) - 1):\n",
    "            t_start = int(s[i]['time'] / 1000)  # inclusive\n",
    "            t_end = int(s[i + 1]['time'] / 1000)  # exclusive\n",
    "\n",
    "            if t_start >= lower_bound and t_end <= upper_bound:\n",
    "                add_slide = True\n",
    "            elif (t_start < lower_bound and t_end > lower_bound\n",
    "                      and t_end < upper_bound):\n",
    "                add_slide = True\n",
    "            elif (t_start < upper_bound and t_end > upper_bound\n",
    "                      and t_start >= lower_bound):\n",
    "                add_slide = True\n",
    "            else:\n",
    "                add_slide = False\n",
    "\n",
    "            if add_slide:\n",
    "                slides.append(RS_CDN.format(\n",
    "                    video_id=video_id,\n",
    "                    slide_type=slide_size,\n",
    "                    slide_id=s[i]['image']['name'],\n",
    "                    format=s[i]['image'].get('extname', slide_format).strip('.')))\n",
    "        # TODO: i may be undefined for only one slide (see line #466)\n",
    "        else:  # handle the last slide\n",
    "            t_start = int(s[i + 1]['time'] / 1000)  # inclusive\n",
    "            t_end = None  # exclusive\n",
    "\n",
    "            if t_start >= lower_bound and t_start < upper_bound:\n",
    "                slides.append(RS_CDN.format(\n",
    "                    video_id=video_id,\n",
    "                    slide_type=slide_size,\n",
    "                    slide_id=s[i + 1]['image']['name'],\n",
    "                    format=s[i + 1]['image'].get('extname', slide_format).strip('.')))\n",
    "    else:\n",
    "        slides = [RS_CDN.format(video_id=video_id,\n",
    "                                slide_type=slide_size,\n",
    "                                slide_id=s['image']['name'],\n",
    "                                format=s['image'].get('extname', slide_format).strip('.'))\n",
    "                  for s in slide_meta['slides']]\n",
    "\n",
    "    return slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a533cb9",
   "metadata": {},
   "source": [
    "This function allows to generate a list of slide URLs for a given SlidesLive presentation.\n",
    "You can filter the slides by *time* or *ID* if your talk is in the middle of a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6f59b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://rs.slideslive.com/38956531/slides/01074.png?h=1080&f=png\n",
      "https://rs.slideslive.com/38956531/slides/01163.png?h=1080&f=png\n"
     ]
    }
   ],
   "source": [
    "my_id_bounds = (1074, 1163)\n",
    "\n",
    "my_urls = get_urls(my_sl_id, slides_metadata,\n",
    "                   slide=my_id_bounds)\n",
    "print(my_urls[0])\n",
    "print(my_urls[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ab351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "_get_urls_meta = {\n",
    "    'slides': [\n",
    "        {'time': 0, 'image': {'name': '1'}},\n",
    "        {'time': 5000, 'image': {'name': '2'}},\n",
    "        {'time': 10000, 'image': {'name': '3'}},\n",
    "        {'time': 15000, 'image': {'name': '4'}},\n",
    "        {'time': 20000, 'image': {'name': '5'}}\n",
    "    ]\n",
    "}\n",
    "_get_urls_meta_1 = {\n",
    "    'slides': [\n",
    "        {'type': 'image', 'time': 0, 'image': {'name': '1', 'extname': '.jpg'}},\n",
    "        {'type': 'image', 'time': 5000, 'image': {'name': '2', 'extname': '.jpg'}},\n",
    "        {'type': 'image', 'time': 10000, 'image': {'name': '3', 'extname': '.jpg'}},\n",
    "        {'type': 'image', 'time': 15000, 'image': {'name': '4', 'extname': '.jpg'}},\n",
    "        {'type': 'image', 'time': 20000, 'image': {'name': '5', 'extname': '.jpg'}}\n",
    "    ]\n",
    "}\n",
    "\n",
    "test_fail(get_urls,\n",
    "          args=['xxx', _get_urls_meta],\n",
    "          kwargs=dict(slide_type='xxx', slide=None, time=None),\n",
    "          contains='Numeric slide bound (slide) must be a 2-tuple.')\n",
    "test_fail(get_urls,\n",
    "          args=['xxx', _get_urls_meta],\n",
    "          kwargs=dict(slide_type='xxx', slide=(0, 6), time=None),\n",
    "          contains='Time-based slide bound (time) must be a 2-tuple.')\n",
    "test_fail(get_urls,\n",
    "          args=['xxx', _get_urls_meta],\n",
    "          kwargs=dict(slide_type='xxx', slide=(0, 6), time=(10, 15)),\n",
    "          contains='Both slide and time bounds cannot be used simultaneously.')\n",
    "test_fail(get_urls,\n",
    "          args=['xxx', _get_urls_meta],\n",
    "          kwargs=dict(slide_type='xsmall', slide=(0, 6)),\n",
    "          contains='The slide type (slide_type=xsmall) can only be one of the '\n",
    "                   'following: \"large\", \"medium\", \"small\", \"xlarge\".')\n",
    "test_fail(get_urls,\n",
    "          args=['xxx', _get_urls_meta],\n",
    "          kwargs=dict(slide_type='small', slide=(0, 6), slide_format='abc'),\n",
    "          contains='The slide format (slide_format=abc) can either be \"png\" or \"webp\".')\n",
    "\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small')\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='png')\n",
    "                for i in range(1, 6)])\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', slide_format='webp')\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='webp')\n",
    "                for i in range(1, 6)])\n",
    "assert (get_urls('xxx', _get_urls_meta_1, slide_type='small')\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='jpg')\n",
    "                for i in range(1, 6)])\n",
    "assert (get_urls('xxx', _get_urls_meta_1, slide_type='small', slide_format='webp')\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='jpg')\n",
    "                for i in range(1, 6)])\n",
    "\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', slide=(2, 4))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='png')\n",
    "                for i in range(2, 5)])\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', slide=(0, 4))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='png')\n",
    "                for i in range(1, 5)])\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', slide=(-50, 4))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='png')\n",
    "                for i in range(1, 5)])\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', slide=(-50, 50))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='png')\n",
    "                for i in range(1, 6)])\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', slide=(1, 5))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='png')\n",
    "                for i in range(1, 6)])\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', slide=(4, 5))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='png')\n",
    "                for i in range(4, 6)])\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', slide=(4, 6))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='png')\n",
    "                for i in range(4, 6)])\n",
    "\n",
    "# precise slides\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', time=(0, 5))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=1, format='png')])\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', time=(5, 10))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=2, format='png')])\n",
    "# in-between slides\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', time=(3, 17))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='png')\n",
    "                for i in range(1, 5)])\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', time=(5, 17))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='png')\n",
    "                for i in range(2, 5)])\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', time=(3, 20))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=i, format='png')\n",
    "                for i in range(1, 5)])\n",
    "# out of range\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', time=(-50, 5))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=1, format='png')])\n",
    "assert (get_urls('xxx', _get_urls_meta, slide_type='small', time=(20, 1000))\n",
    "            == [RS_CDN.format(video_id='xxx', slide_type=SIZE_MAP['small'], slide_id=5, format='png')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91127733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def download_slides(url_list, sleep_time=.2, jobs=16,\n",
    "                    directory=None, technique='python'):\n",
    "    \"\"\"\n",
    "    Downloads files from a list of URLs (`url_list`).\n",
    "\n",
    "    The destination directory is either `slides` created\n",
    "    in the current working directory, or a path specified\n",
    "    via the `directory` parameter.\n",
    "\n",
    "    Three different download strategies are supported:\n",
    "\n",
    "    * `technique='python'` -- downloads the images through\n",
    "      Python's `requests` library one by one, pausing for\n",
    "      `sleep_time` (`0.2` seconds, by default) after each\n",
    "      download.\n",
    "    * `technique='wget'` -- downloads the images by invoking\n",
    "      `wget` for each image in the list, pausing for\n",
    "      `sleep_time` (`0.2` seconds, by default) after each\n",
    "      download.\n",
    "    * `technique='wget+parallel'` -- downloads multiple images\n",
    "      simultaneously -- specified by the `jobs` parameter\n",
    "      (`16`, by default)-- by invoking `wget` thorugh `parallel`.\n",
    "    \"\"\"\n",
    "    if technique not in ('python', 'wget', 'wget+parallel'):\n",
    "        raise ValueError('The download `technique` should be one of: '\n",
    "                         'python, wget, wget+parallel.')\n",
    "\n",
    "    if directory is None:\n",
    "        slides_dir = os.path.join(os.getcwd(), 'slides')\n",
    "    else:\n",
    "        slides_dir = directory\n",
    "\n",
    "    if os.path.exists(slides_dir):\n",
    "        if not os.path.isdir(slides_dir):\n",
    "            raise RuntimeError(\n",
    "                'The slides destination is a file '\n",
    "                f'and not a directory.\\n({slides_dir})')\n",
    "    else:\n",
    "        os.mkdir(slides_dir)\n",
    "\n",
    "    if technique in ('python', 'wget'):\n",
    "        for url in url_list:\n",
    "            clean_url = urllib.parse.urljoin(url, urllib.parse.urlparse(url).path)\n",
    "            fn = os.path.basename(clean_url)\n",
    "            fn_path = os.path.join(slides_dir, fn)\n",
    "\n",
    "            if os.path.exists(fn_path):\n",
    "                if os.path.isfile(fn_path):\n",
    "                    warnings.warn(f'File {fn_path} already exists; skipping download.')\n",
    "                else:\n",
    "                    warnings.warn(f'The file path -- {fn_path} -- is a directory; '\n",
    "                                  'skipping download.')\n",
    "            else:\n",
    "                if technique == 'python':\n",
    "                    with open(fn_path, 'wb') as f:\n",
    "                        r = requests.get(url)\n",
    "                        f.write(r.content)\n",
    "                else:\n",
    "                    assert technique == 'wget'\n",
    "                    stream = os.popen(f'wget -P {slides_dir} {url}')\n",
    "                    print(stream.read())\n",
    "                time.sleep(sleep_time)\n",
    "    else:\n",
    "        assert technique == 'wget+parallel'\n",
    "        with tempfile.NamedTemporaryFile(mode='w') as parallel_file:\n",
    "            parallel_file.write('\\n'.join(url_list))\n",
    "            parallel_file.seek(0)\n",
    "\n",
    "            stream = os.popen(f'parallel -j {jobs} wget -P {slides_dir} < {parallel_file.name}')\n",
    "            print(stream.read())\n",
    "\n",
    "            for f in [f for f in os.listdir(slides_dir) if os.path.isfile(os.path.join(slides_dir, f))]:\n",
    "                clean_f = urllib.parse.urlparse(f).path\n",
    "                if not os.path.exists(clean_f):\n",
    "                    os.rename(os.path.join(slides_dir, f), os.path.join(slides_dir, clean_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b274dd1f",
   "metadata": {},
   "source": [
    "You can use this function ot download slides to a selected directory.\n",
    "If you want to speed yp the process, install `wget` and `parallel`,\n",
    "and use the `technique='wget+parallel'` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4b335",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slides = [\n",
    "    'https://rs.slideslive.com/38956531/slides/00793.png?h=1080&f=png',\n",
    "    'https://rs.slideslive.com/38956531/slides/00794.png?h=1080&f=png'\n",
    "]\n",
    "download_slides(my_slides, directory='my_slides_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d99b61-1f9b-4b36-9ead-0bf3dfd025b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00793.png  00794.png\n"
     ]
    }
   ],
   "source": [
    "ls my_slides_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6619ec58-35da-4f51-bd6b-2268161bebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-02-26 21:12:22--  https://rs.slideslive.com/38956531/slides/00793.png?h=1080&f=png\n",
      "Resolving rs.slideslive.com (rs.slideslive.com)... 2606:4700:21::8d65:780b, 2606:4700:21::8d65:780a, 141.101.120.11, ...\n",
      "Connecting to rs.slideslive.com (rs.slideslive.com)|2606:4700:21::8d65:780b|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 299659 (293K) [image/png]\n",
      "Saving to: ‘my_slides_dir_wget-parallel/00793.png?h=1080&f=png’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 17% 7.69M 0s\n",
      "    50K .......... .......... .......... .......... .......... 34% 4.26M 0s\n",
      "   100K .......... .......... .......... .......... .......... 51% 2.90M 0s\n",
      "   150K .......... .......... .......... .......... .......... 68% 4.02M 0s\n",
      "   200K .......... .......... .......... .......... .......... 85% 5.58M 0s\n",
      "   250K .......... .......... .......... .......... ..        100% 4.79M=0.06s\n",
      "\n",
      "2024-02-26 21:12:23 (4.45 MB/s) - ‘my_slides_dir_wget-parallel/00793.png?h=1080&f=png’ saved [299659/299659]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-02-26 21:12:22--  https://rs.slideslive.com/38956531/slides/00794.png?h=1080&f=png\n",
      "Resolving rs.slideslive.com (rs.slideslive.com)... 2606:4700:21::8d65:780b, 2606:4700:21::8d65:780a, 141.101.120.11, ...\n",
      "Connecting to rs.slideslive.com (rs.slideslive.com)|2606:4700:21::8d65:780b|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 300396 (293K) [image/png]\n",
      "Saving to: ‘my_slides_dir_wget-parallel/00794.png?h=1080&f=png’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 17%  828K 0s\n",
      "    50K .......... .......... .......... .......... .......... 34% 1.94M 0s\n",
      "   100K .......... .......... .......... .......... .......... 51%  108M 0s\n",
      "   150K .......... .......... .......... .......... .......... 68% 12.1M 0s\n",
      "   200K .......... .......... .......... .......... .......... 85%  973K 0s\n",
      "   250K .......... .......... .......... .......... ...       100%  118M=0.1s\n",
      "\n",
      "2024-02-26 21:12:24 (2.02 MB/s) - ‘my_slides_dir_wget-parallel/00794.png?h=1080&f=png’ saved [300396/300396]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "download_slides(my_slides, directory='my_slides_dir_wget-parallel', technique='wget+parallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af122b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00793.png  00794.png\n"
     ]
    }
   ],
   "source": [
    "ls my_slides_dir_wget-parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "CWD = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ad828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "_dl_slides = [\n",
    "    'https://rs.slideslive.com/38956531/slides/00800.png?h=1080&f=png',\n",
    "    'https://rs.slideslive.com/38956531/slides/00801.png?h=1080&f=png'\n",
    "]\n",
    "_dl_files = [os.path.basename(urllib.parse.urljoin(i, urllib.parse.urlparse(i).path))\n",
    "             for i in _dl_slides]\n",
    "\n",
    "test_fail(download_slides,\n",
    "          args=[_dl_slides],\n",
    "          kwargs=dict(technique='xxx'),\n",
    "          contains='The download `technique` should be one of: '\n",
    "                   'python, wget, wget+parallel.')\n",
    "with tempfile.NamedTemporaryFile() as tf:\n",
    "    test_fail(download_slides,\n",
    "              args=[_dl_slides],\n",
    "              kwargs=dict(technique='wget+parallel', directory=tf.name),\n",
    "              contains='The slides destination is a file '\n",
    "                       f'and not a directory.\\n({tf.name})')\n",
    "# creating dirs\n",
    "with tempfile.TemporaryDirectory() as tempdir:\n",
    "    with _cd_temp(tempdir):\n",
    "        assert os.getcwd().endswith(tempdir)\n",
    "        assert os.path.exists(tempdir) and os.path.isdir(tempdir)\n",
    "\n",
    "        # dirs\n",
    "        ## default dir\n",
    "        download_slides(_dl_slides)\n",
    "        assert os.path.exists(tempdir) and os.path.isdir(tempdir)\n",
    "        temp_slides_dir = os.path.join(tempdir, 'slides')\n",
    "        assert os.path.exists(temp_slides_dir) and os.path.isdir(temp_slides_dir)\n",
    "        for i in _dl_files:\n",
    "            i_f = os.path.join(tempdir, 'slides', i)\n",
    "            assert os.path.exists(i_f) and os.path.isfile(i_f)\n",
    "        ## named dir\n",
    "        download_slides(_dl_slides, directory='foo')\n",
    "        temp_slides_dir = os.path.join(tempdir, 'foo')\n",
    "        assert os.path.exists(temp_slides_dir) and os.path.isdir(temp_slides_dir)\n",
    "        for i in _dl_files:\n",
    "            i_f = os.path.join(tempdir, 'foo', i)\n",
    "            assert os.path.exists(i_f) and os.path.isfile(i_f)\n",
    "\n",
    "        # warn\n",
    "        test_warns(lambda: download_slides(_dl_slides, directory='foo'))\n",
    "\n",
    "    assert os.getcwd() == CWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271d306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ffmpeg_concat_script(slide_meta, slide_folder=None, last_duration=None,\n",
    "                         slide=(None, None), time=(None, None)):\n",
    "    \"\"\"\n",
    "    Builds an ffmpeg frame concatination string from slide metadata.\n",
    "    Since the duration of the very last slide cannot be inferred,\n",
    "    it lasts for a user-specified amount of time\n",
    "    (`last_diration`, `5` by default).\n",
    "\n",
    "    `slide_folder` specifies the location of the slide images.\n",
    "    By default, it is the `slides` folder in the current\n",
    "    working directory.\n",
    "\n",
    "    A subset of slides may be extracted with this function using either\n",
    "    the `slide` or `time` parameter (but not both simultaneously).\n",
    "\n",
    "    The `slide` parameter takes a range of slides to be extracted based\n",
    "    on the slide ID numbers visible in a SlidesLive presentation.\n",
    "    For example, `slide=(5, 7)` to extract slides 5--7, **inclusive**;\n",
    "    `slide=(5, None)` to extract from slide 5 **onwards**; or\n",
    "    `slide=(None, 6)` to extract up to slide 6 **inclusive**.\n",
    "\n",
    "    The `time` parameter takes a range of time (visible in a SlidesLive\n",
    "    presentation) for which slides are to be extracted.\n",
    "    For example, `time=(5, 10)` to extract slides starting at second 5\n",
    "    (**inclusive**) and ending before second 10 (**exclusive**);\n",
    "    `time=(5, None)` to extract from second 5 **onwards**; or\n",
    "    `time=(None, 50)` to extract up to second 60 **exclusive**.\n",
    "    \"\"\"\n",
    "    def _slide_exists(_slide_file):\n",
    "        _f = os.path.join(slide_folder, f\"{_slide_file}.png\")\n",
    "        _f = os.path.abspath(_f)\n",
    "        if not os.path.exists(_f) or not os.path.isfile(_f):\n",
    "            raise RuntimeError(f'{_f} file does not exist.')\n",
    "        return _f\n",
    "\n",
    "    if not isinstance(slide, tuple) or len(slide) != 2:\n",
    "        raise TypeError('Numeric slide bound (slide) must be a 2-tuple.')\n",
    "    if not isinstance(time, tuple) or len(time) != 2:\n",
    "        raise TypeError('Time-based slide bound (time) must be a 2-tuple.')\n",
    "\n",
    "    slide_given = slide[0] is not None or slide[1] is not None\n",
    "    time_given = time[0] is not None or time[1] is not None\n",
    "    if slide_given and time_given:\n",
    "        raise RuntimeError('Both slide and time bounds cannot be used simultaneously.')\n",
    "\n",
    "    if slide_folder is None:\n",
    "        slide_folder = os.path.join(os.getcwd(), 'slides')\n",
    "    if not os.path.exists(slide_folder) or not os.path.isdir(slide_folder):\n",
    "        raise ValueError(f'Given directory does not exist: {slide_folder}.')\n",
    "\n",
    "    ffmpeg = []\n",
    "    glob_start, glob_end = None, None\n",
    "    if slide_given:\n",
    "        lower_bound = -float('inf') if slide[0] is None else slide[0]\n",
    "        upper_bound = float('inf') if slide[1] is None else slide[1]\n",
    "        for i in range(len(slide_meta['slides']) - 1):\n",
    "            i_ = i + 1\n",
    "            if i_ >= lower_bound and i_ <= upper_bound:\n",
    "                t_start = slide_meta['slides'][i]['time']\n",
    "                t_end = slide_meta['slides'][i_]['time']\n",
    "                t_duration = (t_end - t_start) / 1000\n",
    "                f = _slide_exists(slide_meta['slides'][i]['image']['name'])\n",
    "                ffmpeg += [f\"file '{f}'\", f'duration {t_duration:.3f}']\n",
    "\n",
    "                glob_start = t_start / 1000 if glob_start is None else glob_start\n",
    "                glob_end = t_end / 1000\n",
    "        # TODO: i may be undefined for only one slide (see line #466)\n",
    "        else:\n",
    "            i_ = i + 2\n",
    "            if i_ >= lower_bound and i_ <= upper_bound:\n",
    "                f = _slide_exists(slide_meta['slides'][i + 1]['image']['name'])\n",
    "                last_duration = 5 if last_duration is None else last_duration\n",
    "                ffmpeg += [f\"file '{f}'\", f'duration {last_duration:.3f}']\n",
    "\n",
    "                _glob = slide_meta['slides'][i + 1]['time']\n",
    "                glob_start = _glob / 1000 if glob_start is None else glob_start\n",
    "                glob_end = (_glob / 1000) + last_duration\n",
    "    elif time_given:\n",
    "        lower_bound = -float('inf') if time[0] is None else time[0]\n",
    "        upper_bound = float('inf') if time[1] is None else time[1]\n",
    "        for i in range(len(slide_meta['slides']) - 1):\n",
    "            t_start = int(slide_meta['slides'][i]['time'] / 1000)  # inclusive\n",
    "            t_end = int(slide_meta['slides'][i + 1]['time'] / 1000)  # exclusive\n",
    "\n",
    "            if t_start >= lower_bound and t_end <= upper_bound:\n",
    "                add_slide = True\n",
    "                t_start_ = slide_meta['slides'][i]['time']\n",
    "                t_end_ = slide_meta['slides'][i + 1]['time']\n",
    "            elif (t_start < lower_bound and t_end > lower_bound\n",
    "                      and t_end < upper_bound):\n",
    "                add_slide = True\n",
    "                t_start_ = lower_bound * 1000\n",
    "                t_end_ = slide_meta['slides'][i + 1]['time']\n",
    "            elif (t_start < upper_bound and t_end > upper_bound\n",
    "                      and t_start >= lower_bound):\n",
    "                add_slide = True\n",
    "                t_start_ = slide_meta['slides'][i]['time']\n",
    "                t_end_ = upper_bound * 1000\n",
    "            else:\n",
    "                add_slide = False\n",
    "                t_start_ = None\n",
    "                t_end_ = None\n",
    "\n",
    "            if add_slide:\n",
    "                f = _slide_exists(slide_meta['slides'][i]['image']['name'])\n",
    "                t_duration = (t_end_ - t_start_) / 1000\n",
    "                ffmpeg += [f\"file '{f}'\", f'duration {t_duration:.3f}']\n",
    "\n",
    "                glob_start = t_start_ / 1000 if glob_start is None else glob_start\n",
    "                glob_end = t_end_ / 1000\n",
    "        # TODO: i may be undefined for only one slide (see line #466)\n",
    "        else:  # handle the last slide\n",
    "            t_start = int(slide_meta['slides'][i + 1]['time'] / 1000)  # inclusive\n",
    "            t_end = None  # exclusive\n",
    "            t_start_ = slide_meta['slides'][i + 1]['time'] / 1000\n",
    "            if t_start >= lower_bound and t_start < upper_bound:\n",
    "                f = _slide_exists(slide_meta['slides'][i + 1]['image']['name'])\n",
    "                if upper_bound == float('inf'):\n",
    "                    duration = 5 if last_duration is None else last_duration\n",
    "                else:\n",
    "                    if last_duration is None:\n",
    "                        duration = upper_bound - t_start\n",
    "                    else:\n",
    "                        if t_start + last_duration < upper_bound:\n",
    "                            duration = last_duration\n",
    "                        else:\n",
    "                            duration = upper_bound - t_start\n",
    "                ffmpeg += [f\"file '{f}'\", f'duration {duration:.3f}']\n",
    "\n",
    "                glob_start = t_start_ if glob_start is None else glob_start\n",
    "                glob_end = t_start_ + duration\n",
    "    else:\n",
    "        _slides_iter = len(slide_meta['slides']) - 1\n",
    "        for i in range(_slides_iter):\n",
    "            i_ = i + 1\n",
    "            t_start = slide_meta['slides'][i]['time']\n",
    "            t_end = slide_meta['slides'][i_]['time']\n",
    "            t_duration = (t_end - t_start) / 1000\n",
    "\n",
    "            f = _slide_exists(slide_meta['slides'][i]['image']['name'])\n",
    "            ffmpeg += [f\"file '{f}'\", f'duration {t_duration:.3f}']\n",
    "\n",
    "            glob_start = t_start / 1000 if glob_start is None else glob_start\n",
    "        else:\n",
    "            if not _slides_iter:\n",
    "                i = -1\n",
    "                assert slide_meta['slides'][i + 1]['time'] == 0\n",
    "                glob_start = 0.0\n",
    "            f = _slide_exists(slide_meta['slides'][i + 1]['image']['name'])\n",
    "            last_duration = 5 if last_duration is None else last_duration\n",
    "            ffmpeg += [f\"file '{f}'\", f'duration {last_duration:.3f}']\n",
    "\n",
    "            glob_end = (slide_meta['slides'][i + 1]['time'] / 1000) + last_duration\n",
    "\n",
    "    # NOTE: the last image must be duplicated without duration due to a bug\n",
    "    #       in ffmpeg (https://trac.ffmpeg.org/wiki/Slideshow)\n",
    "    if len(ffmpeg) > 1:\n",
    "        ffmpeg.append(ffmpeg[-2])\n",
    "\n",
    "    return '\\n'.join(ffmpeg), glob_start, glob_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648fec9c",
   "metadata": {},
   "source": [
    "This function creates a script for concatenating images into a video.\n",
    "\n",
    "> It can be executed with the `ffmpeg -safe 0 -f concat -i ffmpeg_concat_script.txt -vsync vfr slides.mp4`\n",
    "> command.\n",
    "> See the `compose_ffmpeg_video` function for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70de114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file '/Users/kacper/Desktop/myslideslive/src/my_slides_dir/00793.png'\n",
      "duration 29.023\n",
      "file '/Users/kacper/Desktop/myslideslive/src/my_slides_dir/00794.png'\n",
      "duration 1.994\n",
      "file '/Users/kacper/Desktop/myslideslive/src/my_slides_dir/00794.png'\n",
      "\n",
      "10611.802--10642.819\n"
     ]
    }
   ],
   "source": [
    "my_slides_ffmpeg, start_second, end_second = ffmpeg_concat_script(\n",
    "    slides_metadata,\n",
    "    slide_folder='my_slides_dir',\n",
    "    slide=(793, 794))\n",
    "\n",
    "print(my_slides_ffmpeg)\n",
    "print(f'\\n{start_second}--{end_second}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b8519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "_sl_files = [f\"{i['image']['name']}.png\"\n",
    "             for i in _get_urls_meta['slides']]\n",
    "_sl_dur = [5, 5, 5, 5, 5]\n",
    "\n",
    "test_fail(ffmpeg_concat_script,\n",
    "          args=[_get_urls_meta],\n",
    "          kwargs=dict(slide=None, time=None),\n",
    "          contains='Numeric slide bound (slide) must be a 2-tuple.')\n",
    "test_fail(ffmpeg_concat_script,\n",
    "          args=[_get_urls_meta],\n",
    "          kwargs=dict(slide=(0, 6), time=None),\n",
    "          contains='Time-based slide bound (time) must be a 2-tuple.')\n",
    "test_fail(ffmpeg_concat_script,\n",
    "          args=[_get_urls_meta],\n",
    "          kwargs=dict(slide=(0, 6), time=(10, 15)),\n",
    "          contains='Both slide and time bounds cannot be used simultaneously.')\n",
    "test_fail(ffmpeg_concat_script,\n",
    "          args=[_get_urls_meta],\n",
    "          kwargs=dict(slide_folder='test_xyz'),\n",
    "          contains='Given directory does not exist: test_xyz.')\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tempdir:\n",
    "    with _cd_temp(tempdir):\n",
    "        assert os.getcwd().endswith(tempdir)\n",
    "        assert os.path.exists(tempdir) and os.path.isdir(tempdir)\n",
    "        os.mkdir('slides')\n",
    "        for i in _sl_files:\n",
    "            _sl_path = os.path.join(tempdir, 'slides', i)\n",
    "            with open(_sl_path, 'w') as f:\n",
    "                f.write('')\n",
    "            assert os.path.isfile(_sl_path)\n",
    "\n",
    "        # no bound\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta)\n",
    "        assert _gs == 0 and _ge == 25\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]  # the range - 1\n",
    "        for i in range(0, len(_ffmpeg_list) - 1, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_sl_dur[i_]:.3f}'\n",
    "\n",
    "        # item bound\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, slide=(2, 4))\n",
    "        assert _gs == 5 and _ge == 20\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        for i in range(2, 8, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i - 2].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i - 2 + 1] == f'duration {_sl_dur[i_]:.3f}'\n",
    "        ##\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, slide=(0, 4))\n",
    "        assert _gs == 0 and _ge == 20\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        for i in range(0, 8, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_sl_dur[i_]:.3f}'\n",
    "        ##\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, slide=(-50, 4))\n",
    "        assert _gs == 0 and _ge == 20\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        for i in range(0, 8, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_sl_dur[i_]:.3f}'\n",
    "        ##\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, slide=(-50, 50))\n",
    "        assert _gs == 0 and _ge == 25\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]  # the range - 1\n",
    "        for i in range(0, len(_ffmpeg_list) - 1, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_sl_dur[i_]:.3f}'\n",
    "        ##\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, slide=(1, 5))\n",
    "        assert _gs == 0 and _ge == 25\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        for i in range(0, 10, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_sl_dur[i_]:.3f}'\n",
    "        ##\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, slide=(4, 5))\n",
    "        assert _gs == 15 and _ge == 25\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        for i in range(6, 10, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i - 6].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i - 6 + 1] == f'duration {_sl_dur[i_]:.3f}'\n",
    "        ##\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, slide=(4, 6))\n",
    "        assert _gs == 15 and _ge == 25\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        for i in range(6, 10, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i - 6].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i - 6 + 1] == f'duration {_sl_dur[i_]:.3f}'\n",
    "\n",
    "        # time bound\n",
    "        ## precise slides\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(0, 5))\n",
    "        assert _gs == 0 and _ge == 5\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        for i in range(0, 2, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_sl_dur[i_]:.3f}'\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(5, 10))\n",
    "        assert _gs == 5 and _ge == 10\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        for i in range(2, 4, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i - 2].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i - 2 + 1] == f'duration {_sl_dur[i_]:.3f}'\n",
    "        ## in-between slides\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(3, 17))\n",
    "        assert _gs == 3 and _ge == 17\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        _timing = [2, 5, 5, 2, None]\n",
    "        for i in range(0, 8, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_timing[i_]:.3f}'\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(5, 17))\n",
    "        assert _gs == 5 and _ge == 17\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        _timing = [None, 5, 5, 2, None]\n",
    "        for i in range(2, 8, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i - 2].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i - 2 + 1] == f'duration {_timing[i_]:.3f}'\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(3, 20))\n",
    "        assert _gs == 3 and _ge == 20\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        _timing = [2, 5, 5, 5, None]\n",
    "        for i in range(0, 8, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_timing[i_]:.3f}'\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(3, 22))\n",
    "        assert _gs == 3 and _ge == 22\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        _timing = [2, 5, 5, 5, 2]\n",
    "        for i in range(0, 10, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_timing[i_]:.3f}'\n",
    "        ## out of range\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(3, 25))\n",
    "        assert _gs == 3 and _ge == 25\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        _timing = [2, 5, 5, 5, 5]\n",
    "        for i in range(0, 10, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_timing[i_]:.3f}'\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(3, 30))\n",
    "        assert _gs == 3 and _ge == 30\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        _timing = [2, 5, 5, 5, 10]\n",
    "        for i in range(0, 10, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_timing[i_]:.3f}'\n",
    "        ### last_duration\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(3, 20), last_duration=20)\n",
    "        assert _gs == 3 and _ge == 20\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        _timing = [2, 5, 5, 5, None]\n",
    "        for i in range(0, 8, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_timing[i_]:.3f}'\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(3, 22), last_duration=20)\n",
    "        assert _gs == 3 and _ge == 22\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        _timing = [2, 5, 5, 5, 2]\n",
    "        for i in range(0, 10, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_timing[i_]:.3f}'\n",
    "        ## out of range\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(3, 25), last_duration=3)\n",
    "        assert _gs == 3 and _ge == 23\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        _timing = [2, 5, 5, 5, 3]\n",
    "        for i in range(0, 10, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_timing[i_]:.3f}'\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(3, 30), last_duration=20)\n",
    "        assert _gs == 3 and _ge == 30\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        _timing = [2, 5, 5, 5, 10]\n",
    "        for i in range(0, 10, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_timing[i_]:.3f}'\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(3, None), last_duration=20)\n",
    "        assert _gs == 3 and _ge == 40\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        _timing = [2, 5, 5, 5, 20]\n",
    "        for i in range(0, 8, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_timing[i_]:.3f}'\n",
    "        ###\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(-50, 5))\n",
    "        assert _gs == 0 and _ge == 5\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        _timing = [5, None, None, None, None]\n",
    "        for i in range(0, 2, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i + 1] == f'duration {_timing[i_]:.3f}'\n",
    "        _ffmpeg_script, _gs, _ge = ffmpeg_concat_script(_get_urls_meta, time=(20, 1000))\n",
    "        assert _gs == 20 and _ge == 1000\n",
    "        _ffmpeg_list = _ffmpeg_script.split('\\n')\n",
    "        assert _ffmpeg_list[-1] == _ffmpeg_list[-3]\n",
    "        _timing = [None, None, None, None, 980]\n",
    "        for i in range(8, 10, 2):\n",
    "            i_ = int(i / 2)\n",
    "            assert _ffmpeg_list[i - 8].endswith(f\"{_sl_files[i_]}'\")\n",
    "            assert _ffmpeg_list[i - 8 + 1] == f'duration {_timing[i_]:.3f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc868acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compose_ffmpeg_video(ffmpeg_script, video_file=None):\n",
    "    \"\"\"\n",
    "    Builds video slides from an ffmpeg script using the\n",
    "    `ffmpeg -safe 0 -f concat -i ffmpeg_concat.txt -vsync vfr slides.mp4` command.\n",
    "    \"\"\"\n",
    "    if video_file is None:\n",
    "        video_file = 'slides.mp4'\n",
    "    if not video_file.endswith('.mp4'):\n",
    "        video_file += '.mp4'\n",
    "    if os.path.exists(video_file):\n",
    "        raise RuntimeError(f'{video_file} video file already exists.')\n",
    "\n",
    "    ffmpeg_script_list = ffmpeg_script.split('\\n')\n",
    "    assert len(ffmpeg_script_list) > 2, '3 elements constitute a single frame'\n",
    "    if len(ffmpeg_script_list) == 3:\n",
    "        img = ffmpeg_script_list[0]\n",
    "        assert img.startswith(\"file '\") and img.endswith(\"'\")\n",
    "        img = img[6:-1]\n",
    "\n",
    "        duration = ffmpeg_script_list[1]\n",
    "        assert duration.startswith('duration ')\n",
    "        duration = duration[9:]\n",
    "\n",
    "        # -c:v libx264\n",
    "        stream = os.popen(f'ffmpeg -loop 1 -i {img} -t {duration} {video_file}')\n",
    "        print(stream.read())\n",
    "    else:\n",
    "        with tempfile.NamedTemporaryFile(mode='w') as tf:\n",
    "            tf.write(ffmpeg_script)\n",
    "            tf.seek(0)\n",
    "\n",
    "            # -pix_fmt yuv420p\n",
    "            stream = os.popen(f'ffmpeg -safe 0 -f concat -i {tf.name} -vsync vfr {video_file}')\n",
    "            print(stream.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2937b5",
   "metadata": {},
   "source": [
    "Alternatively, you can save the ffmpeg script to a file yourself and\n",
    "execute this command from your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a3eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_3 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "-vsync is deprecated. Use -fps_mode\n",
      "Input #0, concat, from '/var/folders/6h/dm1bx0zs1m16d1d1dfrjd6mc0000gn/T/tmpyrqeytmx':\n",
      "  Duration: N/A, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, pal8(pc, gbr/unknown/unknown), 1920x1080 [SAR 3779:3779 DAR 16:9], 25 fps, 25 tbr, 25 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x11f63da60] using SAR=1/1\n",
      "[libx264 @ 0x11f63da60] using cpu capabilities: ARMv8 NEON\n",
      "[libx264 @ 0x11f63da60] profile High 4:4:4 Predictive, level 4.0, 4:4:4, 8-bit\n",
      "[libx264 @ 0x11f63da60] 264 - core 164 r3108 31e19f9 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'slides.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(tv, progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "[out#0/mp4 @ 0x11f63ca20] video:267kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.340439%\n",
      "frame=    3 fps=0.0 q=-1.0 Lsize=     268kB time=00:00:00.00 bitrate=N/A speed=   0x    \n",
      "[libx264 @ 0x11f63da60] frame I:1     Avg QP:10.17  size:198121\n",
      "[libx264 @ 0x11f63da60] frame P:1     Avg QP:15.70  size: 73001\n",
      "[libx264 @ 0x11f63da60] frame B:1     Avg QP:16.83  size:  1366\n",
      "[libx264 @ 0x11f63da60] consecutive B-frames: 33.3% 66.7%  0.0%  0.0%\n",
      "[libx264 @ 0x11f63da60] mb I  I16..4: 39.6% 46.2% 14.2%\n",
      "[libx264 @ 0x11f63da60] mb P  I16..4:  3.9%  3.7%  1.6%  P16..4: 11.3%  3.6%  3.4%  0.0%  0.0%    skip:72.5%\n",
      "[libx264 @ 0x11f63da60] mb B  I16..4:  0.2%  0.0%  0.0%  B16..8:  6.8%  0.2%  0.0%  direct: 0.9%  skip:92.0%  L0:11.7% L1:88.2% BI: 0.1%\n",
      "[libx264 @ 0x11f63da60] 8x8 transform intra:45.7% inter:67.7%\n",
      "[libx264 @ 0x11f63da60] coded y,u,v intra: 24.1% 14.4% 15.6% inter: 7.6% 2.6% 3.8%\n",
      "[libx264 @ 0x11f63da60] i16 v,h,dc,p: 74% 21%  4%  0%\n",
      "[libx264 @ 0x11f63da60] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 39% 19% 32%  1%  1%  2%  2%  2%  2%\n",
      "[libx264 @ 0x11f63da60] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 24% 26% 18%  4%  5%  6%  6%  5%  6%\n",
      "[libx264 @ 0x11f63da60] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x11f63da60] kb/s:66.14\n"
     ]
    }
   ],
   "source": [
    "compose_ffmpeg_video(my_slides_ffmpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef545fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--@ 1 kacper  staff  274107 26 Feb 21:12 slides.mp4\n"
     ]
    }
   ],
   "source": [
    "ls -la slides.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78004cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "with tempfile.TemporaryDirectory() as tempdir:\n",
    "    with _cd_temp(tempdir):\n",
    "        assert os.getcwd().endswith(tempdir)\n",
    "        assert os.path.exists(tempdir) and os.path.isdir(tempdir)\n",
    "\n",
    "        _sl_path = os.path.join(tempdir, 'slides.mp4')\n",
    "        with open(_sl_path, 'w') as f:\n",
    "            f.write('')\n",
    "        assert os.path.isfile(_sl_path)\n",
    "\n",
    "        test_fail(compose_ffmpeg_video,\n",
    "                  args=[''],\n",
    "                  kwargs=dict(video_file=None),\n",
    "                  contains='slides.mp4 video file already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ea58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SlidesLive():\n",
    "    \"\"\"\n",
    "    Simplifies SlidesLive interaction.\n",
    "\n",
    "    Should be initialised with SlidesLive presentation URL (`video_url`).\n",
    "    Optionally, a destination folder for downloading slides may be specified\n",
    "    (`slides_folder`).\n",
    "\n",
    "    See `url2id`, `get_sl_info` and `get_slide_metadata` for more details.\n",
    "    \"\"\"\n",
    "    def __init__(self, video_url, slides_folder=None):\n",
    "        \"\"\"Initialises SlidesLive.\"\"\"\n",
    "        self.slides_dir = slides_folder\n",
    "        self.slides_video = None\n",
    "        self.slide = None\n",
    "        self.time = None\n",
    "\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "\n",
    "        self.video_id, self.video_name = url2id(video_url)\n",
    "        self.video_description = get_sl_info(self.video_id)\n",
    "\n",
    "        # try XML approach first\n",
    "        try_xml = True\n",
    "        if 'slides_xml_url' in self.video_description and try_xml:\n",
    "            try:\n",
    "                meta = get_slide_metadata(\n",
    "                    self.video_description['slides_xml_url'], approach='xml')\n",
    "            except RuntimeError as e:\n",
    "                if str(e) == f'Request failed ({self.video_description[\"slides_xml_url\"]})':\n",
    "                    try_xml = False\n",
    "                else:\n",
    "                    raise e\n",
    "        else:\n",
    "            try_xml = False\n",
    "\n",
    "        # try JSON approach if XML failed\n",
    "        try_json = True\n",
    "        if 'slides_json_url' in self.video_description and not try_xml:\n",
    "            try:\n",
    "                meta = get_slide_metadata(\n",
    "                    self.video_description['slides_json_url'], approach='json')\n",
    "            except RuntimeError as e:\n",
    "                if str(e) == f'Request failed ({self.video_description[\"slides_json_url\"]})':\n",
    "                    try_json = False\n",
    "                else:\n",
    "                    raise e\n",
    "        else:\n",
    "            try_json = False\n",
    "\n",
    "        # raise an error if both failed\n",
    "        if not try_xml and not try_json:\n",
    "            raise RuntimeError('Failed to retrieve XML or JSON slides metadata')\n",
    "\n",
    "        self.video_metadata = meta\n",
    "\n",
    "    def get_slide_urls(self, slide_type='xlarge', slide=None, time=None):\n",
    "        \"\"\"Returns a list of slide URLs -- see `get_urls` for more details.\"\"\"\n",
    "        if self.slide is None and slide is None:\n",
    "            self.slide = (None, None)\n",
    "        elif self.slide is None and slide is not None:\n",
    "            self.slide = slide\n",
    "        elif self.slide is not None and slide is None:\n",
    "            pass\n",
    "        elif self.slide is not None and slide is not None:\n",
    "            self.slide = slide\n",
    "\n",
    "        if self.time is None and time is None:\n",
    "            self.time = (None, None)\n",
    "        elif self.time is None and time is not None:\n",
    "            self.time = time\n",
    "        elif self.time is not None and time is None:\n",
    "            pass\n",
    "        elif self.time is not None and time is not None:\n",
    "            self.time = time\n",
    "\n",
    "        return get_urls(self.video_id, self.video_metadata,\n",
    "                        slide_type=slide_type,\n",
    "                        slide=self.slide, time=self.time)\n",
    "\n",
    "    def download_slides(self, slide_type='xlarge', slide=None, time=None,\n",
    "                        sleep_time=.2, jobs=16, directory=None, technique='python'):\n",
    "        \"\"\"Downloads a collection of slides -- see `get_urls` and `download_slide` for more details.\"\"\"\n",
    "        if directory is not None:\n",
    "            self.slides_dir = directory\n",
    "        elif self.slides_dir is None:\n",
    "            self.slides_dir = self.video_id\n",
    "\n",
    "        url_list = self.get_slide_urls(slide_type=slide_type,\n",
    "                                       slide=slide, time=time)\n",
    "        download_slides(url_list, sleep_time=sleep_time, jobs=jobs,\n",
    "                       directory=self.slides_dir, technique=technique)\n",
    "\n",
    "    def get_ffmpeg_script(self, slide_folder=None, last_duration=None,\n",
    "                          slide=None, time=None):\n",
    "        \"\"\"Composes ffmpeg script -- see `ffmpeg_concat_script` for more details.\"\"\"\n",
    "        if slide_folder is not None:\n",
    "            self.slides_dir = slide_folder\n",
    "        elif self.slides_dir is None:\n",
    "            self.slides_dir = self.video_id\n",
    "\n",
    "        if self.slide is None and slide is None:\n",
    "            self.slide = (None, None)\n",
    "        elif self.slide is None and slide is not None:\n",
    "            self.slide = slide\n",
    "        elif self.slide is not None and slide is None:\n",
    "            pass\n",
    "        elif self.slide is not None and slide is not None:\n",
    "            self.slide = slide\n",
    "\n",
    "        if self.time is None and time is None:\n",
    "            self.time = (None, None)\n",
    "        elif self.time is None and time is not None:\n",
    "            self.time = time\n",
    "        elif self.time is not None and time is None:\n",
    "            pass\n",
    "        elif self.time is not None and time is not None:\n",
    "            self.time = time\n",
    "\n",
    "        return ffmpeg_concat_script(self.video_metadata, slide_folder=self.slides_dir,\n",
    "                                    last_duration=last_duration, slide=self.slide, time=self.time)\n",
    "\n",
    "    def compose_video(self, video_file=None,\n",
    "                      slide_folder=None, last_duration=None,\n",
    "                      slide=None, time=None):\n",
    "        \"\"\"Builds slides video -- see `ffmpeg_concat_script` and `compose_ffmpeg_video` for more details.\"\"\"\n",
    "        if video_file is not None:\n",
    "            self.slides_video = video_file\n",
    "        elif self.slides_dir is None and self.slides_video is None:\n",
    "            self.slides_video = f'{self.video_id}.mp4'\n",
    "        elif self.slides_dir is not None and self.slides_video is None:\n",
    "            self.slides_video = f'{self.slides_dir}.mp4'\n",
    "\n",
    "        if slide_folder is not None:\n",
    "            self.slides_dir = slide_folder\n",
    "        elif slide_folder is None and self.slides_dir is None:\n",
    "            self.slides_dir = self.video_id\n",
    "\n",
    "        ffmpeg_script, self.start_time, self.end_time = self.get_ffmpeg_script(\n",
    "            slide_folder=self.slides_dir, last_duration=last_duration,\n",
    "            slide=slide, time=time)\n",
    "        compose_ffmpeg_video(ffmpeg_script, video_file=self.slides_video)\n",
    "\n",
    "        print(f'\\n\\nExtracted time segment in seconds:\\n    {self.start_time}--{self.end_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f9c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"SlidesLive.get_slide_urls\" class=\"doc_header\"><code>SlidesLive.get_slide_urls</code><a href=\"__main__.py#L55\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>SlidesLive.get_slide_urls</code>(**`slide_type`**=*`'xlarge'`*, **`slide`**=*`None`*, **`time`**=*`None`*)\n",
       "\n",
       "Returns a list of slide URLs -- see [`get_urls`](/myslideslive/slideslive.html#get_urls) for more details."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SlidesLive.get_slide_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72e261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"SlidesLive.download_slides\" class=\"doc_header\"><code>SlidesLive.download_slides</code><a href=\"__main__.py#L79\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>SlidesLive.download_slides</code>(**`slide_type`**=*`'xlarge'`*, **`slide`**=*`None`*, **`time`**=*`None`*, **`sleep_time`**=*`0.2`*, **`jobs`**=*`16`*, **`directory`**=*`None`*, **`technique`**=*`'python'`*)\n",
       "\n",
       "Downloads a collection of slides -- see [`get_urls`](/myslideslive/slideslive.html#get_urls) and `download_slide` for more details."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SlidesLive.download_slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57798ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"SlidesLive.get_ffmpeg_script\" class=\"doc_header\"><code>SlidesLive.get_ffmpeg_script</code><a href=\"__main__.py#L92\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>SlidesLive.get_ffmpeg_script</code>(**`slide_folder`**=*`None`*, **`last_duration`**=*`None`*, **`slide`**=*`None`*, **`time`**=*`None`*)\n",
       "\n",
       "Composes ffmpeg script -- see [`ffmpeg_concat_script`](/myslideslive/slideslive.html#ffmpeg_concat_script) for more details."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SlidesLive.get_ffmpeg_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726192d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"SlidesLive.compose_video\" class=\"doc_header\"><code>SlidesLive.compose_video</code><a href=\"__main__.py#L121\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>SlidesLive.compose_video</code>(**`video_file`**=*`None`*, **`slide_folder`**=*`None`*, **`last_duration`**=*`None`*, **`slide`**=*`None`*, **`time`**=*`None`*)\n",
       "\n",
       "Builds slides video -- see [`ffmpeg_concat_script`](/myslideslive/slideslive.html#ffmpeg_concat_script) and [`compose_ffmpeg_video`](/myslideslive/slideslive.html#compose_ffmpeg_video) for more details."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SlidesLive.compose_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2826485",
   "metadata": {},
   "source": [
    "The `SlidesLive` class helps to navigate through the `myslideslive.slideslive` module functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "msl = SlidesLive('https://slideslive.com/38956531/'\n",
    "                 'beyond-static-papers-'\n",
    "                 'rethinking-how-we-share-scientific-understanding-in-ml',\n",
    "                 slides_folder='beyond-static-papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a12e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "msl.download_slides(slide=(1074, 1075))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e0e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01074.png  01075.png\n"
     ]
    }
   ],
   "source": [
    "ls {msl.slides_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d620a8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Extracted time segment in seconds:\n",
      "    15215.247--15250.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_3 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "-vsync is deprecated. Use -fps_mode\n",
      "Input #0, concat, from '/var/folders/6h/dm1bx0zs1m16d1d1dfrjd6mc0000gn/T/tmpocb94vw3':\n",
      "  Duration: N/A, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, pal8(pc, gbr/unknown/unknown), 1920x1080 [SAR 3779:3779 DAR 16:9], 25 fps, 25 tbr, 25 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x14d649260] using SAR=1/1\n",
      "[libx264 @ 0x14d649260] using cpu capabilities: ARMv8 NEON\n",
      "[libx264 @ 0x14d649260] profile High 4:4:4 Predictive, level 4.0, 4:4:4, 8-bit\n",
      "[libx264 @ 0x14d649260] 264 - core 164 r3108 31e19f9 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'beyond-static-papers.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(tv, progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "[out#0/mp4 @ 0x14d648220] video:104kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.858732%\n",
      "frame=    3 fps=0.0 q=-1.0 Lsize=     105kB time=00:00:00.00 bitrate=N/A speed=   0x    \n",
      "[libx264 @ 0x14d649260] frame I:2     Avg QP: 7.54  size: 52678\n",
      "[libx264 @ 0x14d649260] frame P:1     Avg QP:12.59  size:   392\n",
      "[libx264 @ 0x14d649260] mb I  I16..4: 54.4% 36.2%  9.5%\n",
      "[libx264 @ 0x14d649260] mb P  I16..4:  0.3%  0.0%  0.0%  P16..4:  0.6%  0.0%  0.0%  0.0%  0.0%    skip:99.1%\n",
      "[libx264 @ 0x14d649260] 8x8 transform intra:36.1% inter:32.3%\n",
      "[libx264 @ 0x14d649260] coded y,u,v intra: 13.6% 8.2% 9.3% inter: 0.1% 0.0% 0.0%\n",
      "[libx264 @ 0x14d649260] i16 v,h,dc,p: 87% 10%  3%  1%\n",
      "[libx264 @ 0x14d649260] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 50% 14% 29%  2%  1%  1%  1%  1%  1%\n",
      "[libx264 @ 0x14d649260] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 41% 24% 14%  4%  4%  3%  4%  3%  3%\n",
      "[libx264 @ 0x14d649260] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x14d649260] ref P L0: 95.3%  4.7%\n",
      "[libx264 @ 0x14d649260] kb/s:19.23\n"
     ]
    }
   ],
   "source": [
    "msl.compose_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946927b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--@ 1 kacper  staff  107350 26 Feb 21:49 beyond-static-papers.mp4\n"
     ]
    }
   ],
   "source": [
    "ls -la {msl.slides_video}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616956c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec2a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "msl1 = SlidesLive('https://slideslive.com/38988636/'\n",
    "                  '24-sparsity-on-gpu-tensor-cores',\n",
    "                  slides_folder='sparsity-on-gpu-tensor-cores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82d841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6h/dm1bx0zs1m16d1d1dfrjd6mc0000gn/T/ipykernel_74244/1050395881.py:50: UserWarning: File sparsity-on-gpu-tensor-cores/Al9BWavE9eBg6Cbt.png already exists; skipping download.\n",
      "  warnings.warn(f'File {fn_path} already exists; skipping download.')\n",
      "/var/folders/6h/dm1bx0zs1m16d1d1dfrjd6mc0000gn/T/ipykernel_74244/1050395881.py:50: UserWarning: File sparsity-on-gpu-tensor-cores/2afSaynhm8Bny1UR.png already exists; skipping download.\n",
      "  warnings.warn(f'File {fn_path} already exists; skipping download.')\n",
      "/var/folders/6h/dm1bx0zs1m16d1d1dfrjd6mc0000gn/T/ipykernel_74244/1050395881.py:50: UserWarning: File sparsity-on-gpu-tensor-cores/NatAtRXM3yJfYDZE.png already exists; skipping download.\n",
      "  warnings.warn(f'File {fn_path} already exists; skipping download.')\n"
     ]
    }
   ],
   "source": [
    "msl1.download_slides(slide=(30, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4ef52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0y6lL6DLzQDW61hc.png  Al9BWavE9eBg6Cbt.png  RKfA7o8KZcOoOIN2.png\n",
      "2afSaynhm8Bny1UR.png  NatAtRXM3yJfYDZE.png  yju18VFM0VQbavac.png\n"
     ]
    }
   ],
   "source": [
    "ls {msl1.slides_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12275491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.1.0.2.5)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_3 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "-vsync is deprecated. Use -fps_mode\n",
      "Input #0, concat, from '/var/folders/6h/dm1bx0zs1m16d1d1dfrjd6mc0000gn/T/tmpitmtrzsu':\n",
      "  Duration: N/A, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, pal8(pc, gbr/unknown/unknown), 1920x1080 [SAR 2835:2835 DAR 16:9], 25 fps, 25 tbr, 25 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x13483ff70] using SAR=1/1\n",
      "[libx264 @ 0x13483ff70] using cpu capabilities: ARMv8 NEON\n",
      "[libx264 @ 0x13483ff70] profile High 4:4:4 Predictive, level 4.0, 4:4:4, 8-bit\n",
      "[libx264 @ 0x13483ff70] 264 - core 164 r3108 31e19f9 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'sparsity-on-gpu-tensor-cores.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(tv, progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.31.102 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=    0 fps=0.0 q=0.0 size=       0kB time=N/A bitrate=N/A speed=N/A    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Extracted time segment in seconds:\n",
      "    1253.12--1417.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/mp4 @ 0x13483b140] video:405kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.243480%\n",
      "frame=    7 fps=0.0 q=-1.0 Lsize=     406kB time=00:02:28.80 bitrate=  22.4kbits/s speed= 744x    \n",
      "[libx264 @ 0x13483ff70] frame I:1     Avg QP: 9.12  size:162985\n",
      "[libx264 @ 0x13483ff70] frame P:2     Avg QP:11.14  size: 43707\n",
      "[libx264 @ 0x13483ff70] frame B:4     Avg QP:13.62  size: 40932\n",
      "[libx264 @ 0x13483ff70] consecutive B-frames: 14.3% 28.6%  0.0% 57.1%\n",
      "[libx264 @ 0x13483ff70] mb I  I16..4: 50.4% 22.3% 27.3%\n",
      "[libx264 @ 0x13483ff70] mb P  I16..4: 11.0%  7.3%  6.5%  P16..4:  6.4%  1.3%  0.9%  0.0%  0.0%    skip:66.5%\n",
      "[libx264 @ 0x13483ff70] mb B  I16..4:  1.9%  0.7%  5.2%  B16..8: 11.9%  1.3%  0.5%  direct: 2.4%  skip:76.1%  L0:35.1% L1:62.5% BI: 2.4%\n",
      "[libx264 @ 0x13483ff70] 8x8 transform intra:22.0% inter:47.4%\n",
      "[libx264 @ 0x13483ff70] coded y,u,v intra: 30.1% 20.9% 19.4% inter: 4.7% 1.9% 1.4%\n",
      "[libx264 @ 0x13483ff70] i16 v,h,dc,p: 72% 24%  4%  0%\n",
      "[libx264 @ 0x13483ff70] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 48% 10% 41%  0%  0%  0%  0%  0%  0%\n",
      "[libx264 @ 0x13483ff70] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 37% 21% 16%  3%  4%  5%  5%  4%  4%\n",
      "[libx264 @ 0x13483ff70] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x13483ff70] ref P L0: 66.4%  2.5% 24.4%  6.8%\n",
      "[libx264 @ 0x13483ff70] ref B L0: 90.9%  9.1%\n",
      "[libx264 @ 0x13483ff70] ref B L1: 95.9%  4.1%\n",
      "[libx264 @ 0x13483ff70] kb/s:19.36\n"
     ]
    }
   ],
   "source": [
    "msl1.compose_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a85a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--@ 1 kacper  staff  415828 26 Feb 21:53 sparsity-on-gpu-tensor-cores.mp4\n"
     ]
    }
   ],
   "source": [
    "ls -la {msl1.slides_video}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a8192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a45f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
